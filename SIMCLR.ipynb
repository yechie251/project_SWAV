{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R1pehi-TdnIG"},"outputs":[],"source":["import os\n","import logging\n","import time\n","from datetime import timedelta\n","import pandas as pd\n","\n","\n","class LogFormatter:\n","    def __init__(self):\n","        self.start_time = time.time()\n","\n","    def format(self, record):\n","        elapsed_seconds = round(record.created - self.start_time)\n","\n","        prefix = \"%s - %s - %s\" % (\n","            record.levelname,\n","            time.strftime(\"%x %X\"),\n","            timedelta(seconds=elapsed_seconds),\n","        )\n","        message = record.getMessage()\n","        message = message.replace(\"\\n\", \"\\n\" + \" \" * (len(prefix) + 3))\n","        return \"%s - %s\" % (prefix, message) if message else \"\"\n","\n","\n","def create_logger(filepath, rank):\n","    \"\"\"\n","    Create a logger.\n","    Use a different log file for each process.\n","    \"\"\"\n","    # create log formatter\n","    log_formatter = LogFormatter()\n","\n","    # create file handler and set level to debug\n","    if filepath is not None:\n","        if rank > 0:\n","            filepath = \"%s-%i\" % (filepath, rank)\n","        file_handler = logging.FileHandler(filepath, \"a\")\n","        file_handler.setLevel(logging.DEBUG)\n","        file_handler.setFormatter(log_formatter)\n","\n","    # create console handler and set level to info\n","    console_handler = logging.StreamHandler()\n","    console_handler.setLevel(logging.INFO)\n","    console_handler.setFormatter(log_formatter)\n","\n","    # create logger and set level to debug\n","    logger = logging.getLogger()\n","    logger.handlers = []\n","    logger.setLevel(logging.DEBUG)\n","    logger.propagate = False\n","    if filepath is not None:\n","        logger.addHandler(file_handler)\n","    logger.addHandler(console_handler)\n","\n","    # reset logger elapsed time\n","    def reset_time():\n","        log_formatter.start_time = time.time()\n","\n","    logger.reset_time = reset_time\n","\n","    return logger\n","\n","\n","class PD_Stats(object):\n","    \"\"\"\n","    Log stuff with pandas library\n","    \"\"\"\n","\n","    def __init__(self, path, columns):\n","        self.path = path\n","\n","        # reload path stats\n","        if os.path.isfile(self.path):\n","            self.stats = pd.read_pickle(self.path)\n","\n","            # check that columns are the same\n","            assert list(self.stats.columns) == list(columns)\n","\n","        else:\n","            self.stats = pd.DataFrame(columns=columns)\n","\n","    def update(self, row, save=True):\n","        self.stats.loc[len(self.stats.index)] = row\n","\n","        # save the statistics\n","        if save:\n","            self.stats.to_pickle(self.path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RiOEHnrOdnWJ"},"outputs":[],"source":["import random\n","from logging import getLogger\n","\n","from PIL import ImageFilter\n","import numpy as np\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","logger = getLogger()\n","\n","\n","class MultiCropDataset(datasets.ImageFolder):\n","    def __init__(\n","        self,\n","        data_path,\n","        size_crops,\n","        nmb_crops,\n","        min_scale_crops,\n","        max_scale_crops,\n","        split=None,\n","        return_index=False,\n","    ):\n","        super(MultiCropDataset, self).__init__(data_path)\n","        assert len(size_crops) == len(nmb_crops)\n","        assert len(min_scale_crops) == len(nmb_crops)\n","        assert len(max_scale_crops) == len(nmb_crops)\n","\n","        self.split = split\n","\n","        # True to ILSVRC2012_img_val\n","        num_classes = 1000\n","        samples_per_class = 50\n","        p_train = int(0.7*samples_per_class)\n","        p_val = int(0.2*samples_per_class)\n","        p_test = int(0.1*samples_per_class)\n","\n","        if split == 'train':\n","            indices = []\n","            for class_idx in range(num_classes):\n","                class_start_idx = class_idx * samples_per_class\n","                class_indices = list(range(class_start_idx, class_start_idx + p_train))\n","                indices.extend(class_indices)\n","\n","            self.samples = [self.samples[i] for i in indices]\n","        elif split == 'val':\n","            indices = []\n","            for class_idx in range(num_classes):\n","                class_start_idx = class_idx * samples_per_class\n","                class_indices = list(range(class_start_idx + p_train, class_start_idx + p_train + p_val))\n","                indices.extend(class_indices)\n","\n","            self.samples = [self.samples[i] for i in indices]\n","        elif split == 'test':\n","            indices = []\n","            for class_idx in range(num_classes):\n","                class_start_idx = class_idx * samples_per_class\n","                class_indices = list(range(class_start_idx + p_train + p_val, class_start_idx + p_train + p_val + p_test))\n","                indices.extend(class_indices)\n","\n","            self.samples = [self.samples[i] for i in indices]\n","        self.return_index = return_index\n","\n","\n","        color_transform = [get_color_distortion(), PILRandomGaussianBlur()]\n","        mean = [0.485, 0.456, 0.406]\n","        std = [0.228, 0.224, 0.225]\n","        trans = []\n","        if split == 'train':\n","            for i in range(len(size_crops)):\n","                randomresizedcrop = transforms.RandomResizedCrop(\n","                    size_crops[i],\n","                    scale=(min_scale_crops[i], max_scale_crops[i]),\n","                )\n","                trans.extend([transforms.Compose([\n","                    randomresizedcrop,\n","                    transforms.RandomHorizontalFlip(p=0.5),\n","                    transforms.Compose(color_transform),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize(mean=mean, std=std)])\n","                ] * nmb_crops[i])\n","            self.trans = trans\n","        elif split == 'val': # for later supervised training\n","            trans.extend([transforms.Compose([\n","                transforms.RandomResizedCrop(224),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=mean, std=std)])\n","            ])\n","            self.trans = trans\n","        elif split == 'test': # for evaluation\n","            trans.extend([transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=mean, std=std)])\n","            ])\n","            self.trans = trans\n","\n","    def __getitem__(self, index):\n","        if self.split == 'train':\n","            path, _ = self.samples[index]\n","            image = self.loader(path)\n","            multi_crops = list(map(lambda trans: trans(image), self.trans))\n","            if self.return_index:\n","                return index, multi_crops\n","            return multi_crops\n","        else:\n","            path, target = self.samples[index]\n","            image = self.loader(path)\n","            multi_crops = list(map(lambda trans: trans(image), self.trans))\n","            if self.return_index:\n","                return index, multi_crops, target\n","            return multi_crops, target\n","\n","\n","\n","class PILRandomGaussianBlur(object):\n","    \"\"\"\n","    Apply Gaussian Blur to the PIL image. Take the radius and probability of\n","    application as the parameter.\n","    This transform was used in SimCLR - https://arxiv.org/abs/2002.05709\n","    \"\"\"\n","\n","    def __init__(self, p=0.5, radius_min=0.1, radius_max=2.):\n","        self.prob = p\n","        self.radius_min = radius_min\n","        self.radius_max = radius_max\n","\n","    def __call__(self, img):\n","        do_it = np.random.rand() <= self.prob\n","        if not do_it:\n","            return img\n","\n","        return img.filter(\n","            ImageFilter.GaussianBlur(\n","                radius=random.uniform(self.radius_min, self.radius_max)\n","            )\n","        )\n","\n","\n","def get_color_distortion(s=1.0):\n","    # s is the strength of color distortion.\n","    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n","    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n","    rnd_gray = transforms.RandomGrayscale(p=0.2)\n","    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n","    return color_distort"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9nkaRs1dnhL"},"outputs":[],"source":["import argparse\n","from logging import getLogger\n","import pickle\n","import os\n","\n","import numpy as np\n","import torch\n","\n","import torch.distributed as dist\n","\n","FALSY_STRINGS = {\"off\", \"false\", \"0\"}\n","TRUTHY_STRINGS = {\"on\", \"true\", \"1\"}\n","\n","\n","logger = getLogger()\n","\n","\n","def bool_flag(s):\n","    \"\"\"\n","    Parse boolean arguments from the command line.\n","    \"\"\"\n","    if s.lower() in FALSY_STRINGS:\n","        return False\n","    elif s.lower() in TRUTHY_STRINGS:\n","        return True\n","    else:\n","        raise argparse.ArgumentTypeError(\"invalid value for a boolean flag\")\n","\n","\n","def init_distributed_mode(args): # Modified\n","    \"\"\"\n","    Initialize the following variables:\n","        - world_size\n","        - rank\n","    \"\"\"\n","\n","    args.rank = 0  # Since it's single-node training, set rank to 0\n","    args.world_size = torch.cuda.device_count()  # Set world_size to the number of available GPUs\n","\n","    # Try to initialize distributed process group\n","    try:\n","        dist.init_process_group(\n","            backend=\"nccl\",\n","            init_method=\"tcp://localhost:12345\",\n","            world_size=args.world_size,\n","            rank=args.rank,\n","        )\n","    except RuntimeError as e:\n","        # Handle the case when the default process group is already initialized\n","        if \"trying to initialize the default process group twice\" in str(e):\n","            print('default process group is already initialized')\n","            pass  # Ignore the error and continue\n","\n","    # Set cuda device\n","    args.gpu_to_work_on = 0  # Set the GPU device to use (e.g., 0 for the first GPU)\n","    torch.cuda.set_device(args.gpu_to_work_on)\n","\n","    return args\n","\n","# # With TPU\n","# def init_distributed_mode(args):\n","#     \"\"\"\n","#     Initialize the following variables:\n","#         - world_size\n","#         - rank\n","#     \"\"\"\n","\n","#     args.rank = 0  # Since it's single-node training, set rank to 0\n","\n","#     if hasattr(args, 'tpu') and args.tpu:  # Check if TPU is enabled # Find another way\n","#         import torch_xla.core.xla_model as xm\n","\n","#         args.world_size = xm.xrt_world_size()  # Set world_size to the number of available TPUs\n","#         args.rank = xm.get_ordinal()  # Set rank to the current TPU ordinal\n","\n","#         # Initialize the TPU device\n","#         device = xm.xla_device()\n","#         torch.set_default_tensor_type(\"torch.FloatTensor\")\n","#     else:\n","#         args.world_size = torch.cuda.device_count()  # Set world_size to the number of available GPUs\n","\n","#         # Try to initialize the distributed process group\n","#         try:\n","#             dist.init_process_group(\n","#                 backend=\"nccl\",\n","#                 init_method=\"tcp://localhost:12345\",\n","#                 world_size=args.world_size,\n","#                 rank=args.rank,\n","#             )\n","#         except RuntimeError as e:\n","#             # Handle the case when the default process group is already initialized\n","#             if \"trying to initialize the default process group twice\" in str(e):\n","#                 print('default process group is already initialized')\n","#                 pass  # Ignore the error and continue\n","\n","#         # Set the CUDA device\n","#         args.gpu_to_work_on = 0  # Set the GPU device to use (e.g., 0 for the first GPU)\n","#         torch.cuda.set_device(args.gpu_to_work_on)\n","#         device = torch.device(\"cuda\")\n","\n","#     return args, device\n","\n","\n","def initialize_exp(params, *args, dump_params=True):\n","    \"\"\"\n","    Initialize the experience:\n","    - dump parameters\n","    - create checkpoint repo\n","    - create a logger\n","    - create a panda object to keep track of the training statistics\n","    \"\"\"\n","\n","    # dump parameters\n","    if dump_params:\n","        pickle.dump(params, open(os.path.join(params.dump_path, \"params.pkl\"), \"wb\"))\n","\n","    # create repo to store checkpoints\n","    params.dump_checkpoints = os.path.join(params.dump_path, \"checkpoints\")\n","    if not params.rank and not os.path.isdir(params.dump_checkpoints):\n","        os.mkdir(params.dump_checkpoints)\n","\n","    # create a panda object to log loss and acc\n","    training_stats = PD_Stats(\n","        os.path.join(params.dump_path, \"stats\" + str(params.rank) + \".pkl\"), args\n","    )\n","\n","    # create a logger\n","    logger = create_logger(\n","        os.path.join(params.dump_path, \"train.log\"), rank=params.rank\n","    )\n","    logger.info(\"============ Initialized logger ============\")\n","    logger.info(\n","        \"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(params)).items()))\n","    )\n","    logger.info(\"The experiment will be stored in %s\\n\" % params.dump_path)\n","    logger.info(\"\")\n","    return logger, training_stats\n","\n","\n","def restart_from_checkpoint(ckp_paths, run_variables=None, **kwargs):\n","    \"\"\"\n","    Re-start from checkpoint\n","    \"\"\"\n","    # look for a checkpoint in exp repository\n","    if isinstance(ckp_paths, list):\n","        for ckp_path in ckp_paths:\n","            if os.path.isfile(ckp_path):\n","                break\n","    else:\n","        ckp_path = ckp_paths\n","\n","    if not os.path.isfile(ckp_path):\n","        return\n","\n","    logger.info(\"Found checkpoint at {}\".format(ckp_path))\n","\n","    # open checkpoint file\n","    checkpoint = torch.load(\n","        ckp_path, map_location=\"cuda:\" + str(torch.distributed.get_rank() % torch.cuda.device_count())\n","    )\n","\n","    # key is what to look for in the checkpoint file\n","    # value is the object to load\n","    # example: {'state_dict': model}\n","    for key, value in kwargs.items():\n","        if key in checkpoint and value is not None:\n","            try:\n","                msg = value.load_state_dict(checkpoint[key], strict=False)\n","                print(msg)\n","            except TypeError:\n","                msg = value.load_state_dict(checkpoint[key])\n","            logger.info(\"=> loaded {} from checkpoint '{}'\".format(key, ckp_path))\n","        else:\n","            logger.warning(\n","                \"=> failed to load {} from checkpoint '{}'\".format(key, ckp_path)\n","            )\n","\n","    # re load variable important for the run\n","    if run_variables is not None:\n","        for var_name in run_variables:\n","            if var_name in checkpoint:\n","                run_variables[var_name] = checkpoint[var_name]\n","\n","\n","def fix_random_seeds(seed=31):\n","    \"\"\"\n","    Fix random seeds.\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","\n","\n","class AverageMeter(object):\n","    \"\"\"computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        _, pred = output.topk(maxk, 1, True, True)\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True) # correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udOZ9P5FdnuV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(\n","        in_planes,\n","        out_planes,\n","        kernel_size=3,\n","        stride=stride,\n","        padding=dilation,\n","        groups=groups,\n","        bias=False,\n","        dilation=dilation,\n","    )\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    __constants__ = [\"downsample\"]\n","\n","    def __init__(\n","        self,\n","        inplanes,\n","        planes,\n","        stride=1,\n","        downsample=None,\n","        groups=1,\n","        base_width=64,\n","        dilation=1,\n","        norm_layer=None,\n","    ):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    __constants__ = [\"downsample\"]\n","\n","    def __init__(\n","        self,\n","        inplanes,\n","        planes,\n","        stride=1,\n","        downsample=None,\n","        groups=1,\n","        base_width=64,\n","        dilation=1,\n","        norm_layer=None,\n","    ):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.0)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(\n","            self,\n","            block,\n","            layers,\n","            zero_init_residual=False,\n","            groups=1,\n","            widen=1,\n","            width_per_group=64,\n","            replace_stride_with_dilation=None,\n","            norm_layer=None,\n","            normalize=False,\n","            output_dim=0,\n","            hidden_mlp=0,\n","            nmb_prototypes=0,\n","            eval_mode=False,\n","    ):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.eval_mode = eval_mode\n","        self.padding = nn.ConstantPad2d(1, 0.0)\n","\n","        self.inplanes = width_per_group * widen\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\n","                \"replace_stride_with_dilation should be None \"\n","                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n","            )\n","        self.groups = groups\n","        self.base_width = width_per_group\n","\n","        # change padding 3 -> 2 compared to original torchvision code because added a padding layer\n","        num_out_filters = width_per_group * widen\n","        self.conv1 = nn.Conv2d(\n","            3, num_out_filters, kernel_size=7, stride=2, padding=2, bias=False\n","        )\n","        self.bn1 = norm_layer(num_out_filters)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, num_out_filters, layers[0])\n","        num_out_filters *= 2\n","        self.layer2 = self._make_layer(\n","            block, num_out_filters, layers[1], stride=2, dilate=replace_stride_with_dilation[0]\n","        )\n","        num_out_filters *= 2\n","        self.layer3 = self._make_layer(\n","            block, num_out_filters, layers[2], stride=2, dilate=replace_stride_with_dilation[1]\n","        )\n","        num_out_filters *= 2\n","        self.layer4 = self._make_layer(\n","            block, num_out_filters, layers[3], stride=2, dilate=replace_stride_with_dilation[2]\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # normalize output features\n","        self.l2norm = normalize\n","\n","        # projection head\n","        if output_dim == 0:\n","            self.projection_head = None\n","        elif hidden_mlp == 0:\n","            self.projection_head = nn.Linear(num_out_filters * block.expansion, output_dim)\n","        else:\n","            self.projection_head = nn.Sequential(\n","                nn.Linear(num_out_filters * block.expansion, hidden_mlp),\n","                nn.BatchNorm1d(hidden_mlp),\n","                nn.ReLU(inplace=True),\n","                nn.Linear(hidden_mlp, output_dim),\n","            )\n","\n","        # prototype layer\n","        self.prototypes = None\n","        if isinstance(nmb_prototypes, list):\n","            self.prototypes = MultiPrototypes(output_dim, nmb_prototypes)\n","        elif nmb_prototypes > 0:\n","            self.prototypes = nn.Linear(output_dim, nmb_prototypes, bias=False)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(\n","            block(\n","                self.inplanes,\n","                planes,\n","                stride,\n","                downsample,\n","                self.groups,\n","                self.base_width,\n","                previous_dilation,\n","                norm_layer,\n","            )\n","        )\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    groups=self.groups,\n","                    base_width=self.base_width,\n","                    dilation=self.dilation,\n","                    norm_layer=norm_layer,\n","                )\n","            )\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward_backbone(self, x):\n","        x = self.padding(x)\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        if self.eval_mode:\n","            return x\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","\n","        return x\n","\n","    def forward_head(self, x):\n","        if self.projection_head is not None:\n","            x = self.projection_head(x)\n","\n","        if self.l2norm:\n","            x = nn.functional.normalize(x, dim=1, p=2)\n","\n","        if self.prototypes is not None:\n","            return x, self.prototypes(x)\n","        return x\n","\n","    def forward(self, inputs):\n","        if not isinstance(inputs, list):\n","            inputs = [inputs]\n","        idx_crops = torch.cumsum(torch.unique_consecutive(\n","            torch.tensor([inp.shape[-1] for inp in inputs]),\n","            return_counts=True,\n","        )[1], 0)\n","        start_idx = 0\n","        for end_idx in idx_crops:\n","            _out = self.forward_backbone(torch.cat(inputs[start_idx: end_idx]).cuda(non_blocking=True))\n","            if start_idx == 0:\n","                output = _out\n","            else:\n","                output = torch.cat((output, _out))\n","            start_idx = end_idx\n","        return self.forward_head(output)\n","\n","\n","class MultiPrototypes(nn.Module):\n","    def __init__(self, output_dim, nmb_prototypes):\n","        super(MultiPrototypes, self).__init__()\n","        self.nmb_heads = len(nmb_prototypes)\n","        for i, k in enumerate(nmb_prototypes):\n","            self.add_module(\"prototypes\" + str(i), nn.Linear(output_dim, k, bias=False))\n","\n","    def forward(self, x):\n","        out = []\n","        for i in range(self.nmb_heads):\n","            out.append(getattr(self, \"prototypes\" + str(i))(x))\n","        return out\n","\n","\n","def resnet50(**kwargs):\n","    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n","\n","\n","def resnet50w2(**kwargs):\n","    return ResNet(Bottleneck, [3, 4, 6, 3], widen=2, **kwargs)\n","\n","\n","def resnet50w4(**kwargs):\n","    return ResNet(Bottleneck, [3, 4, 6, 3], widen=4, **kwargs)\n","\n","\n","def resnet50w5(**kwargs):\n","    return ResNet(Bottleneck, [3, 4, 6, 3], widen=5, **kwargs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSckKIPNb3aV"},"outputs":[],"source":["import os\n","import time\n","from logging import getLogger\n","import urllib\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data as data\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","logger = getLogger()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wg_ZI_9bcGBg"},"outputs":[],"source":["class Args:\n","    def __init__(self):\n","        #########################\n","        #### main parameters ####\n","        #########################\n","        self.labels_perc = \"10\"  # fine-tune on either 1% or 10% of labels\n","        # change to the path to save results (swav, swav_multicrop, deepcluster, simCLR)\n","        self.dump_path = \"/content/drive/simCLR\"  # experiment dump path for checkpoints and log\n","        self.seed = 31  # seed\n","        self.data_path = '/content/drive/ILSVRC2012_img_val'  # path to imagenet\n","        self.workers = 10  # number of data loading workers\n","\n","        #########################\n","        #### model parameters ###\n","        #########################\n","        self.arch = \"resnet50\"  # convnet architecture\n","        # change to the path of .tar file for evaluation (swav, swav_multicrop, deepcluster, simCLR)\n","        self.pretrained = \"/content/drive/simCLR/checkpoint.pth.tar\"  # path to pretrained weights # might need to remove /checkpoint.pth.tar\n","\n","        #########################\n","        #### optim parameters ###\n","        #########################\n","        self.epochs = 50  # number of total epochs to run\n","        self.batch_size = 32  # batch size per gpu, i.e. how many unique instances per gpu\n","        self.lr = 0.01  # initial learning rate - trunk\n","        self.lr_last_layer = 0.2  # initial learning rate - head\n","        self.decay_epochs = [12, 16]  # Epochs at which to decay learning rate.\n","        self.gamma = 0.2  # lr decay factor\n","\n","        #########################\n","        #### dist parameters ###\n","        #########################\n","        self.dist_url = \"env://\"  # url used to set up distributed training\n","        self.world_size = -1  # number of processes: it is set automatically and should not be passed as an argument\n","        self.rank = 0  # rank of this process: it is set automatically and should not be passed as an argument\n","        self.local_rank = 0  # this argument is not used and should be ignored\n","\n","\n","global eval_args, best_acc\n","eval_args = Args()\n","init_distributed_mode(eval_args)\n","fix_random_seeds(eval_args.seed)\n","logger, training_stats = initialize_exp(\n","    eval_args, \"epoch\", \"loss\", \"prec1\", \"prec5\", \"loss_val\", \"prec1_val\", \"prec5_val\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pezc1RvqcGNC"},"outputs":[],"source":["# Build val set\n","sup_train_set = MultiCropDataset(\n","    data_path=eval_args.data_path,\n","    # ---filler inputs----\n","    size_crops=[1],\n","    nmb_crops=[1],\n","    min_scale_crops=[1],\n","    max_scale_crops=[1],\n","    # --------------------\n","    split='val'\n",")\n","sampler = torch.utils.data.distributed.DistributedSampler(sup_train_set)\n","sup_train_loader = torch.utils.data.DataLoader(\n","    sup_train_set,\n","    sampler=sampler,\n","    batch_size=eval_args.batch_size,\n","    num_workers=eval_args.workers,\n","    pin_memory=True,\n",")\n","\n","# Build test set\n","val_set = MultiCropDataset(\n","    data_path=eval_args.data_path,\n","    # ---filler inputs----\n","    size_crops=[1],\n","    nmb_crops=[1],\n","    min_scale_crops=[1],\n","    max_scale_crops=[1],\n","    # --------------------\n","    split='test'\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","    val_set,\n","    batch_size=eval_args.batch_size,\n","    num_workers=eval_args.workers,\n","    pin_memory=True,\n",")\n","\n","logger.info(\"Building data done with {} images loaded.\".format(len(sup_train_set)))\n","logger.info(\"Building data done with {} images loaded.\".format(len(val_set)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1B1V430cGX0"},"outputs":[],"source":["# build model\n","if eval_args.arch == 'resnet50': model = resnet50(output_dim=1000)\n","elif eval_args.arch == 'resnet50w2': model = resnet50w2(output_dim=1000)\n","elif eval_args.arch == 'resnet50w4': model = resnet50w4(output_dim=1000)\n","elif eval_args.arch == 'resnet50w5': model = resnet50w5(output_dim=1000)\n","\n","# convert batch norm layers\n","model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n","\n","# load weights\n","if os.path.isfile(eval_args.pretrained):\n","    state_dict = torch.load(eval_args.pretrained, map_location=\"cuda:\" + str(eval_args.gpu_to_work_on))\n","    if \"state_dict\" in state_dict:\n","        state_dict = state_dict[\"state_dict\"]\n","    # remove prefixe \"module.\"\n","    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n","    for k, v in model.state_dict().items():\n","        if k not in list(state_dict):\n","            logger.info('key \"{}\" could not be found in provided state dict'.format(k))\n","        elif state_dict[k].shape != v.shape:\n","            logger.info('key \"{}\" is of different shape in model and provided state dict'.format(k))\n","            state_dict[k] = v\n","    msg = model.load_state_dict(state_dict, strict=False)\n","    logger.info(\"Load pretrained model with msg: {}\".format(msg))\n","else:\n","    logger.info(\"No pretrained weights found => training from random weights\")\n","\n","# model to gpu\n","model = model.cuda()\n","model = nn.parallel.DistributedDataParallel(\n","    model,\n","    device_ids=[eval_args.gpu_to_work_on],\n","    find_unused_parameters=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9FBZUzGcGit"},"outputs":[],"source":["# set optimizer\n","trunk_parameters = []\n","head_parameters = []\n","for name, param in model.named_parameters():\n","    if 'head' in name:\n","        head_parameters.append(param)\n","    else:\n","        trunk_parameters.append(param)\n","optimizer = torch.optim.SGD(\n","    [{'params': trunk_parameters},\n","     {'params': head_parameters, 'lr': eval_args.lr_last_layer}],\n","    lr=eval_args.lr,\n","    momentum=0.9,\n","    weight_decay=0,\n",")\n","# set scheduler\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","    optimizer, eval_args.decay_epochs, gamma=eval_args.gamma\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-nk7iMYLcGvS"},"outputs":[],"source":["# Optionally resume from a checkpoint\n","to_restore = {\"epoch\": 0, \"best_acc\": (0., 0.)}\n","restart_from_checkpoint(\n","    os.path.join(eval_args.dump_path, \"checkpoint.pth.tar\"),\n","    run_variables=to_restore,\n","    state_dict=model,\n","    optimizer=optimizer,\n","    scheduler=scheduler,\n",")\n","start_epoch = to_restore[\"epoch\"]\n","best_acc = to_restore[\"best_acc\"]\n","cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rKhmAvgdQPB"},"outputs":[],"source":["def train(model, optimizer, loader, epoch):\n","    \"\"\"\n","    Train the models on the dataset.\n","    \"\"\"\n","    # running statistics\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","\n","    # training statistics\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","    losses = AverageMeter()\n","    end = time.perf_counter()\n","\n","    model.train()\n","    criterion = nn.CrossEntropyLoss().cuda()\n","\n","    for iter_epoch, (inp, target) in enumerate(loader):\n","        # measure data loading time\n","        data_time.update(time.perf_counter() - end)\n","\n","        # move to gpu\n","        inp = inp[0].cuda(non_blocking=True)\n","        target = target.cuda(non_blocking=True)\n","\n","        # forward\n","        output = model(inp)\n","\n","        # compute cross entropy loss\n","        loss = criterion(output, target)\n","\n","        # compute the gradients\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # step\n","        optimizer.step()\n","\n","        # update stats\n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), inp.size(0))\n","        top1.update(acc1[0], inp.size(0))\n","        top5.update(acc5[0], inp.size(0))\n","\n","        batch_time.update(time.perf_counter() - end)\n","        end = time.perf_counter()\n","\n","        # verbose\n","        if eval_args.rank == 0 and iter_epoch % 50 == 0:\n","            logger.info(\n","                \"Epoch[{0}] - Iter: [{1}/{2}]\\t\"\n","                \"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\"\n","                \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n","                \"Prec {top1.val:.3f} ({top1.avg:.3f})\\t\"\n","                \"LR trunk {lr}\\t\"\n","                \"LR head {lr_W}\".format(\n","                    epoch,\n","                    iter_epoch,\n","                    len(loader),\n","                    batch_time=batch_time,\n","                    data_time=data_time,\n","                    loss=losses,\n","                    top1=top1,\n","                    lr=optimizer.param_groups[0][\"lr\"],\n","                    lr_W=optimizer.param_groups[1][\"lr\"],\n","                )\n","            )\n","    return epoch, losses.avg, top1.avg.item(), top5.avg.item()\n","\n","\n","def validate_network(val_loader, model):\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","    global best_acc\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    criterion = nn.CrossEntropyLoss().cuda()\n","\n","    with torch.no_grad():\n","        end = time.perf_counter()\n","        for i, (inp, target) in enumerate(val_loader):\n","\n","            # move to gpu\n","            inp = inp[0].cuda(non_blocking=True)\n","            target = target.cuda(non_blocking=True)\n","\n","            # compute output\n","            output = model(inp)\n","            loss = criterion(output, target)\n","\n","            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","            losses.update(loss.item(), inp.size(0))\n","            top1.update(acc1[0], inp.size(0))\n","            top5.update(acc5[0], inp.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.perf_counter() - end)\n","            end = time.perf_counter()\n","\n","    if top1.avg.item() > best_acc[0]:\n","        best_acc = (top1.avg.item(), top5.avg.item())\n","\n","    if eval_args.rank == 0:\n","        logger.info(\n","            \"Test:\\t\"\n","            \"Time {batch_time.avg:.3f}\\t\"\n","            \"Loss {loss.avg:.4f}\\t\"\n","            \"Acc@1 {top1.avg:.3f}\\t\"\n","            \"Best Acc@1 so far {acc:.1f}\".format(\n","                batch_time=batch_time, loss=losses, top1=top1, acc=best_acc[0]))\n","\n","    return losses.avg, top1.avg.item(), top5.avg.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOoPa2LpdQl5"},"outputs":[],"source":["for epoch in range(start_epoch, eval_args.epochs):\n","\n","    # train the network for one epoch\n","    logger.info(\"============ Starting epoch %i ... ============\" % epoch)\n","\n","    # set samplers\n","    sup_train_loader.sampler.set_epoch(epoch)\n","\n","    scores = train(model, optimizer, sup_train_loader, epoch)\n","    scores_val = validate_network(val_loader, model)\n","    training_stats.update(scores + scores_val)\n","\n","    scheduler.step()\n","\n","    # save checkpoint\n","    if eval_args.rank == 0:\n","        save_dict = {\n","            \"epoch\": epoch + 1,\n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\": optimizer.state_dict(),\n","            \"scheduler\": scheduler.state_dict(),\n","            \"best_acc\": best_acc,\n","        }\n","        torch.save(save_dict, os.path.join(eval_args.dump_path, \"checkpoint.pth.tar\"))\n","\n","logger.info(\"Fine-tuning with {}% of labels completed.\\n\"\n","            \"Test accuracies: top-1 {acc1:.1f}, top-5 {acc5:.1f}\".format(\n","            eval_args.labels_perc, acc1=best_acc[0], acc5=best_acc[1]))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOvnAnvHMW/DgxBQcOEfCao","collapsed_sections":["imNO8kRPdm1B","WncUeXHQdnQc","MsiINox3dnbq","8BKgExtldnm6"],"gpuType":"T4","mount_file_id":"13M5CIbhwOwaHLSZjglKHQqmGoH-KI767","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
